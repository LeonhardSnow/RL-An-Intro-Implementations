{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义4x4网格类,环境\n",
    "class GridMapEnvironment(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 定义状态、动作、收益的取值范围\n",
    "        self._states = np.array(range(16))\n",
    "        self._actions = np.array(['up', 'down', 'left', 'right'])\n",
    "        self._rewards = np.array([-1, 0])\n",
    "        \n",
    "        # 初始化状态\n",
    "        self._state = 0\n",
    "        \n",
    "    # get set 函数，用以访问类内变量\n",
    "    def getStates(self):\n",
    "        return self._states\n",
    "    \n",
    "    def getActions(self):\n",
    "        return self._actions\n",
    "    \n",
    "    def getRewards(self):\n",
    "        return self._rewards\n",
    "    \n",
    "    def getState(self):\n",
    "        return self._state\n",
    "    \n",
    "    def setState(self, state):\n",
    "        assert state in self._states\n",
    "        self._state = state\n",
    "    \n",
    "    # 更新 state\n",
    "    def _updateState(self, act):\n",
    "        assert act in self._actions\n",
    "        act_func = getattr(self, '_' + act)\n",
    "        act_func()\n",
    "        \n",
    "    # action 函数，定义动作对 state 的影响\n",
    "    def _up(self):     \n",
    "        if self._state in [0, 1, 2, 3, 15]:\n",
    "            pass\n",
    "        else:\n",
    "            self._state = self._state - 4\n",
    "    \n",
    "    def _down(self):   \n",
    "        if self._state in [0, 12, 13, 14, 15]:\n",
    "            pass\n",
    "        else:\n",
    "            self._state = self._state + 4\n",
    "    \n",
    "    def _left(self):\n",
    "        if self._state in [0, 4, 8, 12, 15]:\n",
    "            pass\n",
    "        else:\n",
    "            self._state = self._state - 1\n",
    "    \n",
    "    def _right(self):\n",
    "        if self._state in [0, 3, 7, 11, 15]:\n",
    "            pass\n",
    "        else:\n",
    "            self._state = self._state + 1\n",
    "            \n",
    "    def _returnReward(self):\n",
    "        if self._state in [0, 15]:\n",
    "            return 0\n",
    "        else:\n",
    "            revaluation_result = np.resize(state_value, (4, 4))\n",
    "print(evaluation_result)eturn -1\n",
    "    \n",
    "    def takeAction(self, act):\n",
    "        r = self._returnReward()\n",
    "        self._updateState(act)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "policy evaluation result after 1 times: \n",
      "[[ 0. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.]\n",
      " [-1. -1. -1.  0.]]\n",
      "----------------------------------\n",
      "policy evaluation result after 2 times: \n",
      "[[ 0.   -1.75 -2.   -2.  ]\n",
      " [-1.75 -2.   -2.   -2.  ]\n",
      " [-2.   -2.   -2.   -1.75]\n",
      " [-2.   -2.   -1.75  0.  ]]\n",
      "----------------------------------\n",
      "policy evaluation result after 3 times: \n",
      "[[ 0.     -2.4375 -2.9375 -3.    ]\n",
      " [-2.4375 -2.875  -3.     -2.9375]\n",
      " [-2.9375 -3.     -2.875  -2.4375]\n",
      " [-3.     -2.9375 -2.4375  0.    ]]\n",
      "----------------------------------\n",
      "policy evaluation result after 10 times: \n",
      "[[ 0.         -6.13796997 -8.35235596 -8.96731567]\n",
      " [-6.13796997 -7.73739624 -8.42782593 -8.35235596]\n",
      " [-8.35235596 -8.42782593 -7.73739624 -6.13796997]\n",
      " [-8.96731567 -8.35235596 -6.13796997  0.        ]]\n",
      "----------------------------------\n",
      "policy evaluation result after 100 times: \n",
      "[[  0.         -13.94260509 -19.91495107 -21.90482522]\n",
      " [-13.94260509 -17.92507693 -19.91551999 -19.91495107]\n",
      " [-19.91495107 -19.91551999 -17.92507693 -13.94260509]\n",
      " [-21.90482522 -19.91495107 -13.94260509   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 策略评估测试\n",
    "# 设置策略评估环境，value 序列，action 概率分布，折扣系数（i.e.超参数）\n",
    "grid_map = GridMapEnvironment()\n",
    "state_value = np.zeros(grid_map.getStates().size)\n",
    "prob_act = 0.25\n",
    "gamma = 1.0\n",
    "\n",
    "# 策略评估代码，未进行封装（非优化版本）\n",
    "for t in range(100):\n",
    "    # 生成 value 序列 的 copy\n",
    "    state_value_copy = copy.deepcopy(state_value)\n",
    "    # 清空 value 序列 以进行下一轮的 policy evaluation 迭代\n",
    "    state_value = np.zeros(grid_map.getStates().size)\n",
    "    # 对每一个 state 进行策略评估\n",
    "    for s in grid_map.getStates():\n",
    "        for a in (grid_map.getActions()):\n",
    "            grid_map.setState(s)\n",
    "            state_value[s] = state_value[s] + prob_act * (grid_map.takeAction(a) + gamma * state_value_copy[grid_map.getState()])\n",
    "    if t in [0, 1, 2, 9, 99]:\n",
    "        print('----------------------------------')\n",
    "        print('policy evaluation result after ' + str(t + 1) + ' times: ')\n",
    "        print(np.resize(state_value, (4, 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
